{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "Perceptrons are the building blocks of the most common type of artificial neural network: the Multi-Layer Perceptron. In this notebook you will explore how the output of a perceptron changes with respect to its inputs for different activation functions and different weight connections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of some activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear\n",
    "$$output = neta$$\n",
    "\n",
    "Sigmoid\n",
    "$$output = \\frac {1}{1 + e^{-neta}}$$\n",
    "\n",
    "Hyperbolic tangent\n",
    "$$output = \\frac {e^{neta} - e^{-neta}}{e^{neta} + e^{-neta}}$$\n",
    "\n",
    "Gaussian\n",
    "$$output = e^{-neta^{2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(neta):\n",
    "    '''Linear activation function'''\n",
    "    output = neta\n",
    "    return output\n",
    "\n",
    "def sigmoid(neta):\n",
    "    '''Sigmoidal activation function'''\n",
    "    output = 1 / (1 + np.exp(-neta))\n",
    "    return output\n",
    "\n",
    "def htan(neta):\n",
    "    '''Hyperbolic activation function'''\n",
    "    exp = np.exp(neta)\n",
    "    m_exp = np.exp(-neta)\n",
    "    output = (exp - m_exp ) / (exp + m_exp)\n",
    "    return output\n",
    "\n",
    "activation_functions_dict = {'Linear': linear, 'Sigmoid': sigmoid, 'Hyperbolic tangent': htan}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "            ______________\n",
    "           /              \\\n",
    "x __w_x__ j                l \n",
    "  _______ | f_act(I.W + b) |----- output\n",
    "y   w_y   l                j\n",
    "           \\______________/\n",
    "Where:\n",
    "x = input x\n",
    "y = input y\n",
    "b = bias\n",
    "f_act = activation function\n",
    "I = vector of inputs\n",
    "W = vector of weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$output = f\\_act(\\sum_{i=0}^{1}{(I_{i} * W_{i})} + b)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(input_values, weights, bias, activation_function):\n",
    "    '''Computes the output of a perceptron\n",
    "    :param input_values: inputs to the perceptron\n",
    "    :param weights: perceptron parameters (multiply inputs)\n",
    "    :param bias: perceptron parameter (adds to inputs)\n",
    "    :param activation_function: activation function to apply to the weighted sum of inputs\n",
    "    :return: perceptron output'''\n",
    "    neta = np.dot(input_values, weights) + bias\n",
    "    output = activation_function(neta)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to plot the Perceptron output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = np.arange(-1.2, 1.2, 0.1)\n",
    "input_y = np.arange(-1.2, 1.2, 0.1)\n",
    "\n",
    "input_x_matrix, input_y_matrix = np.meshgrid(input_x, input_y)\n",
    "inputs_xy = np.concatenate((input_x_matrix.flatten()[:,np.newaxis], input_y_matrix.flatten()[:,np.newaxis]), axis=1)\n",
    "\n",
    "def plot_perceptron(weight_x, weight_y, bias, activation_function_index):\n",
    "    weights = np.array([weight_x, weight_y])\n",
    "    \n",
    "    activation_function = activation_functions_dict.get(list(activation_functions_dict.keys())[activation_function_index])\n",
    "    output_values = perceptron(inputs_xy, weights, bias, activation_function)\n",
    "    \n",
    "    output_matrix = np.reshape(output_values, input_x_matrix.shape)\n",
    "    \n",
    "    pl.figure(figsize=(8,6))\n",
    "    pl.imshow(np.flipud(output_matrix), interpolation='None', extent=(-1.2,1.2,-1.2,1.2), vmin=-1.0, vmax=1.0)\n",
    "    pl.xlabel('x')\n",
    "    pl.ylabel('y')\n",
    "    pl.colorbar()\n",
    "    pl.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_controls():\n",
    "    weight_x_slider = widgets.FloatSlider(\n",
    "        value=0.5,\n",
    "        min=-1.0,\n",
    "        max=1.0,\n",
    "        step=0.01,\n",
    "        description='Weight x:',\n",
    "    )\n",
    "    weight_y_slider = widgets.FloatSlider(\n",
    "        value=0.5,\n",
    "        min=-1.0,\n",
    "        max=1.0,\n",
    "        step=0.01,\n",
    "        description='Weight y:',\n",
    "    )\n",
    "    bias_slider = widgets.FloatSlider(\n",
    "        value=0.0,\n",
    "        min=-1.0,\n",
    "        max=1.0,\n",
    "        step=0.01,\n",
    "        description='Bias:',\n",
    "    )\n",
    "    activation_function_list = widgets.Dropdown(\n",
    "    options={k:i for i,k in enumerate(activation_functions_dict.keys())},\n",
    "        value=1,\n",
    "        description='Activation function:',\n",
    "    )\n",
    "    return {'weight_x':weight_x_slider, 'weight_y':weight_y_slider, 'bias':bias_slider, 'activation_function_index':activation_function_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the perceptron output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb8109ebda54619a7b097e696908340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='Weight x:', max=1.0, min=-1.0, step=0.01), FloatSlidâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "controls = create_controls()\n",
    "_= interact(plot_perceptron, **controls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use the sliders to change the weights of the perceptron and observe the effects on its output\n",
    "\n",
    "- Select different activation functions and observe the output of the perceptron for different weight configurations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "widgets": {
   "state": {
    "58c340e4b3f74b9a9c47cd9427004420": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
